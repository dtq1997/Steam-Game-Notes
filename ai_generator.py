"""AI ç¬”è®°ç”Ÿæˆå™¨ â€” æ”¯æŒ Anthropic (Claude) å’Œ OpenAI å…¼å®¹ API"""

import json
import re
import ssl
from datetime import datetime

try:
    import urllib.request
    import urllib.error
    _HAS_URLLIB = True
except ImportError:
    _HAS_URLLIB = False


def _get_ssl_context():
    """è·å– SSL ä¸Šä¸‹æ–‡ï¼ŒmacOS Python å®‰è£…åæœªè¿è¡Œè¯ä¹¦è„šæœ¬æ—¶è‡ªåŠ¨ fallback"""
    try:
        ctx = ssl.create_default_context()
        return ctx
    except Exception:
        pass
    ctx = ssl._create_unverified_context()
    return ctx


def _urlopen(req, timeout=30):
    """å°è£… urlopenï¼Œè‡ªåŠ¨å¤„ç† SSL è¯ä¹¦é—®é¢˜"""
    try:
        return urllib.request.urlopen(req, timeout=timeout)
    except urllib.error.URLError as e:
        if "CERTIFICATE_VERIFY_FAILED" in str(e):
            ctx = ssl._create_unverified_context()
            return urllib.request.urlopen(req, timeout=timeout, context=ctx)
        raise


# é»˜è®¤ç³»ç»Ÿæç¤ºè¯ â€” æ¥è‡ªå¯¼è¨€åŒºçš„ã€AI æ’°å†™æ¸¸æˆè¯´æ˜ç¬”è®°çš„æŒ‡å¼•ã€‘
AI_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ª Steam æ¸¸æˆä»‹ç»æ’°å†™åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æ¸¸æˆä¿¡æ¯ï¼Œæ’°å†™ä¸€æ®µå®¢è§‚çš„"æ¸¸æˆè¯´æ˜"ç¬”è®°ã€‚

ç›®æ ‡è¯»è€…ï¼šä¸ä¸€å®šäº†è§£ç‹¬ç«‹æ¸¸æˆæˆ–å•æœºæ¸¸æˆçš„æ™®é€šç©å®¶ã€‚
ç›®çš„ï¼šè®©è¯»è€…å¿«é€Ÿåˆ¤æ–­è¿™ä¸ªæ¸¸æˆæ˜¯å¦ç¬¦åˆè‡ªå·±çš„å…´è¶£ã€‚

æ’°å†™è§„åˆ™ï¼ˆå¿…é¡»å…¨éƒ¨éµå®ˆï¼‰ï¼š
1. å®¢è§‚æè¿°ï¼šä¸èƒ½ç…§æŠ„å•†åº—é¡µé¢çš„å•†ä¸šåŒ–å®£ä¼ è¯­ï¼Œè¦å®¢è§‚åœ°å‘Šè¯‰è¯»è€…è¿™ä¸ªæ¸¸æˆæ˜¯ä»€ä¹ˆã€ç©èµ·æ¥æ˜¯ä»€ä¹ˆæ„Ÿè§‰ã€‚
2. "ç°åœ¨æ‰“å¼€ä¼šæ€æ ·"ï¼šå¿…é¡»å…·ä½“æè¿°"å¦‚æœæˆ‘ç°åœ¨ç«‹åˆ»æ‰“å¼€è¿™ä¸ªæ¸¸æˆï¼Œå‰å‡ åˆ†é’Ÿä¼šçœ‹åˆ°ä»€ä¹ˆã€åšä»€ä¹ˆ"ã€‚è¦å†™åˆ°è¯»è€…è„‘ä¸­èƒ½æµ®ç°ç”»é¢çš„ç¨‹åº¦â€”â€”æ¯”å¦‚"æ‰“å¼€åå…ˆæ˜¯ä¸€æ®µè¿‡åœºåŠ¨ç”»ï¼Œç„¶åè¿›å…¥è§’è‰²åˆ›å»ºï¼Œé€‰å®ŒèŒä¸šåç›´æ¥è¢«æ‰“è¿›ä¸€ç‰‡é›ªåŸï¼Œæ²¡æœ‰ä»»ä½•æç¤ºï¼Œä½ éœ€è¦è‡ªå·±æ‘¸ç´¢æ€ä¹ˆæ´»ä¸‹å»"ã€‚âŒ ç»å¯¹ç¦æ­¢ç”¨"ä¸Šæ‰‹éš¾åº¦é€‚ä¸­""éœ€è¦ä¸€å®šå­¦ä¹ æˆæœ¬""æœ‰ä¸€å®šé—¨æ§›"è¿™ç±»æ¨¡ç³Šæ¦‚æ‹¬ä»£æ›¿å…·ä½“æè¿°ã€‚ä½ å¿…é¡»å›ç­”çš„æ˜¯"æˆ‘ä¼šçœ‹åˆ°ä»€ä¹ˆç•Œé¢ã€åšä»€ä¹ˆæ“ä½œã€é‡åˆ°ä»€ä¹ˆçŠ¶å†µ"ï¼Œè€Œé"éš¾ä¸éš¾"ã€‚
3. è®¤çŸ¥èµ„æºä¸æ—¶é—´éœ€æ±‚ï¼šå¿…é¡»è¯´æ˜è¿™ä¸ªæ¸¸æˆéœ€è¦æ€æ ·çš„æ³¨æ„åŠ›æŠ•å…¥ï¼Œè®©è¯»è€…çŸ¥é“è‡ªå·±éœ€è¦ä¸ºå®ƒè…¾å‡ºæ€æ ·çš„ç²¾åŠ›å’Œæ—¶é—´ã€‚æ˜¯å¦éœ€è¦å¤§æ®µè¿ç»­æ—¶é—´ã€æ¯å±€/æ¯æ¬¡æ¸¸ç©å¤§æ¦‚å¤šä¹…ã€‚
4. ç½‘ç»œå£ç¢‘ï¼šå¿…é¡»æåŠè¿™ä¸ªæ¸¸æˆåœ¨ç½‘ç»œä¸Šæ˜¯å¦å—æ¬¢è¿ã€å¤§è‡´è¯„ä»·å¦‚ä½•ã€‚
5. ç¼ºç‚¹ä¸ä¸é€‚äººç¾¤ï¼šå¿…é¡»æœ‰ä¸€å®šç¯‡å¹…ä»‹ç»ç¼ºç‚¹ï¼Œä»¥åŠæ˜ç¡®è¯´æ˜ä¸é€‚åˆä»€ä¹ˆæ ·çš„äººç©ã€‚
6. ä¸ç”¨æœ¯è¯­ã€è¯´äººè¯ï¼šç¦æ­¢ä½¿ç”¨è¯»è€…å¯èƒ½ä¸æ‡‚çš„æœ¯è¯­è€Œä¸åŠ è§£é‡Šã€‚ä¾‹å¦‚ä¸èƒ½ç›´æ¥è¯´"ASCII é£æ ¼ç”»é¢"æˆ–"1-bit é£æ ¼"ï¼Œè€Œåº”è¯¥ç”¨æ²¡ç©è¿‡æ¸¸æˆçš„äººéƒ½èƒ½ç†è§£çš„è¯­è¨€æè¿°ï¼ˆå¦‚"ç”»é¢å‡ ä¹å®Œå…¨ç”±å½©è‰²æ–‡å­—ç¬¦å·æ„æˆâ€”â€”ä½ çš„è§’è‰²æ˜¯ä¸€ä¸ª@ï¼Œæ€ªç‰©æ˜¯å­—æ¯ï¼Œå¢™å£æ˜¯#å·"ï¼‰ã€‚æœ¯è¯­ä¸å¿…åˆ»æ„å›é¿æˆ–åˆ é™¤ï¼Œè§£é‡Šæ¸…æ¥šå³å¯ã€‚
7. æ— éœ€å¼ºè°ƒæ€§ä»·æ¯”ï¼šè¿™äº›æ¸¸æˆå·²åœ¨ç”¨æˆ·åº“ä¸­ï¼Œå±äºå…è´¹å¯ç©ï¼Œç»å¯¹ç¦æ­¢æåŠä»»ä½•ä¸ä»·æ ¼ç›¸å…³çš„å†…å®¹ã€‚ç¦æ­¢ä½¿ç”¨çš„è¯æ±‡åŒ…æ‹¬ä½†ä¸é™äºï¼šä»·æ ¼ã€å”®ä»·ã€åŸä»·ã€æ‰“æŠ˜ã€æŠ˜æ‰£ã€æ€§ä»·æ¯”ã€å€¼ä¸å€¼ã€å®šä»·ã€ä¿ƒé”€ã€åŠä»·ã€ç‰¹æƒ ã€å…¥æ‰‹ã€è´­ä¹°å»ºè®®ã€‚å³ä½¿å‚è€ƒèµ„æ–™ä¸­å¤§é‡æåˆ°è¿™äº›å†…å®¹ï¼Œä½ ä¹Ÿå¿…é¡»å®Œå…¨å¿½ç•¥â€”â€”è¯»è€…å·²ç»æ‹¥æœ‰è¿™ä¸ªæ¸¸æˆï¼Œä»»ä½•ä»·æ ¼è®¨è®ºéƒ½æ˜¯æ— æ„ä¹‰çš„ã€‚
8. é€‚åˆçš„æ¸¸ç©æƒ…æ™¯ï¼šé€‚åˆè‡ªå·±ä¸€ä¸ªäººå•ç‹¬ç©ï¼Ÿè¿˜æ˜¯é€‚åˆè·Ÿå¦ä¸€ä¸ªæœ‹å‹ä¸€èµ·ç©ï¼Ÿé€‚åˆè·Ÿä¸€å¤§ç¾¤æœ‹å‹ç©ï¼Ÿé€‚åˆè·Ÿä»€ä¹ˆç±»å‹çš„äººç©ï¼Ÿé€‚åˆä»€ä¹ˆåœºåˆâ€”â€”æ¯”å¦‚ç¡å‰æ”¾æ¾ã€é€šå‹¤é€”ä¸­ã€è¿˜æ˜¯å‘¨æœ«ç©ºå‡ºä¸€æ•´ä¸ªä¸‹åˆï¼Ÿè¯¸å¦‚æ­¤ç±»ã€‚

âš ï¸ å…³é”®æ ¼å¼è¦æ±‚ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ï¼š
- è¾“å‡ºå¿…é¡»æ˜¯ã€çº¯æ–‡æœ¬å•è¡Œã€‘ï¼Œå³æ•´æ®µè¯´æ˜å†™åœ¨åŒä¸€è¡Œå†…ï¼Œç¦æ­¢æ¢è¡Œã€‚
- ç¦æ­¢ä½¿ç”¨ä»»ä½• BBCode æ ‡ç­¾ï¼ˆ[p] [h1] [b] ç­‰å…¨éƒ¨ç¦æ­¢ï¼‰ã€‚
- ç¦æ­¢ä½¿ç”¨åˆ†æ®µå¼çš„å°æ ‡é¢˜ï¼ˆå¦‚"åˆæ¬¡æ‰“å¼€çš„ä½“éªŒï¼š"ã€"è®¤çŸ¥èµ„æºï¼š"ç­‰ï¼‰ï¼Œ
  è€Œåº”å°†æ‰€æœ‰ä¿¡æ¯è‡ªç„¶èå…¥ä¸€æ®µè¿è´¯çš„å™è¿°ä¸­ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·å¨“å¨“é“æ¥ã€‚
- å¯ä»¥ä½¿ç”¨ emoji è¾…åŠ©æ’ç‰ˆ: ğŸ“Œâœ…âš ï¸ğŸ—ºï¸âš”ï¸ğŸ“ğŸ¯ï¼Œ
  ä½†è¦å…‹åˆ¶ï¼Œä¸è¦æ¯å¥è¯éƒ½åŠ  emojiã€‚
- æ³¨æ„æ§åˆ¶é•¿åº¦ï¼Œå»ºè®® 200-500 å­—å·¦å³ã€‚
- è¿™æ®µçº¯æ–‡æœ¬å°†åŒæ—¶ä½œä¸ºç¬”è®°çš„æ ‡é¢˜å’Œå†…å®¹æ˜¾ç¤ºåœ¨ Steam å®¢æˆ·ç«¯ä¸­ï¼Œ
  æ‰€ä»¥ç¬¬ä¸€å¥è¯åº”è¯¥å…·æœ‰æ¦‚æ‹¬æ€§ï¼ˆå¦‚"XXX æ˜¯ä¸€ä¸ªâ€¦â€¦çš„æ¸¸æˆ"ï¼‰ï¼Œè®©äººä¸€çœ¼èƒ½æŠ“ä½é‡ç‚¹ã€‚

ğŸ“‹ å®Œæˆåè‡ªæŸ¥æ¸…å•ï¼ˆè¾“å‡ºå‰åœ¨å¿ƒé‡Œé€æ¡æ ¸å¯¹ï¼Œæœ‰é—æ¼å¿…é¡»è¡¥ä¸Šï¼‰ï¼š
â–¡ æ˜¯å¦å…·ä½“æè¿°äº†"ç°åœ¨æ‰“å¼€å‰å‡ åˆ†é’Ÿä¼šçœ‹åˆ°ä»€ä¹ˆã€åšä»€ä¹ˆ"ï¼Ÿï¼ˆä¸æ˜¯"ä¸Šæ‰‹éš¾åº¦å¦‚ä½•"ï¼Œè€Œæ˜¯å…·ä½“åœºæ™¯ï¼‰
â–¡ æ˜¯å¦è¯´æ˜äº†æ³¨æ„åŠ›æŠ•å…¥ç¨‹åº¦å’Œå•æ¬¡æ¸¸ç©æ—¶é•¿ï¼Ÿ
â–¡ æ˜¯å¦æåˆ°äº†ç½‘ç»œå£ç¢‘/ç¤¾åŒºè¯„ä»·ï¼Ÿ
â–¡ æ˜¯å¦æœ‰ç¼ºç‚¹å’Œä¸é€‚åˆçš„äººç¾¤ï¼Ÿ
â–¡ æ˜¯å¦æ‰€æœ‰æœ¯è¯­éƒ½é™„å¸¦äº†é€šä¿—è§£é‡Šï¼Œæ²¡æœ‰è®©ä¸æ‡‚æ¸¸æˆçš„è¯»è€…æ„Ÿåˆ°å›°æƒ‘ï¼Ÿ
â–¡ æ˜¯å¦æœ‰æåˆ°é€‚åˆçš„æ¸¸ç©æƒ…æ™¯ï¼ˆè·Ÿè°ç©ã€ä»€ä¹ˆåœºåˆï¼‰ï¼Ÿ
â–¡ æ˜¯å¦å…¨æ–‡éƒ½æ˜¯è‡ªç„¶è¿è´¯çš„å™è¿°ï¼Œæ²¡æœ‰åˆ†æ®µæ ‡é¢˜ï¼Ÿ
â–¡ æ˜¯å¦çº¯æ–‡æœ¬å•è¡Œï¼Œæ²¡æœ‰æ¢è¡Œï¼Ÿ
â–¡ ç¬¬ä¸€å¥è¯æ˜¯å¦æœ‰æ¦‚æ‹¬æ€§ï¼Ÿ
â–¡ ã€å…³é”®ã€‘å…¨æ–‡æ˜¯å¦å®Œå…¨æ²¡æœ‰æåŠä»·æ ¼ã€æ€§ä»·æ¯”ã€å”®ä»·ã€æ‰“æŠ˜ç­‰ä¸é’±æœ‰å…³çš„å†…å®¹ï¼Ÿ

è¯·ç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬å†…å®¹ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€å‰ç¼€ã€æ ‡ç­¾æˆ–æ ¼å¼ç¬¦å·ã€‚"""


# â”€â”€ è”ç½‘æœç´¢æ—¶è¿½åŠ çš„ç³»ç»Ÿæç¤º â”€â”€
AI_WEB_SEARCH_ADDENDUM = """

ğŸ” ä½ å·²è·å¾—è”ç½‘æœç´¢èƒ½åŠ›ã€‚åœ¨æ’°å†™ä¹‹å‰ï¼Œè¯·ä¸»åŠ¨æœç´¢ä»¥ä¸‹ä¿¡æ¯æ¥å¢å¼ºä½ çš„æè¿°è´¨é‡ï¼š
1. è¿™ä¸ªæ¸¸æˆçš„å®é™…æ¸¸ç©ä½“éªŒï¼ˆæœç´¢æ¸¸æˆå + review / gameplay / è¯„æµ‹ï¼‰
2. ç¤¾åŒºå£ç¢‘å’Œå¸¸è§äº‰è®®ï¼ˆæœç´¢æ¸¸æˆå + reddit / è®¨è®º / äº‰è®®ï¼‰
3. å¤§è‡´é€šå…³æ—¶é•¿æˆ–å…¸å‹æ¸¸ç©æ—¶é•¿ï¼ˆæœç´¢æ¸¸æˆå + how long to beat / æ¸¸ç©æ—¶é•¿ï¼‰

ğŸŒ å¤šè¯­è¨€æœç´¢ç­–ç•¥ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š
- å¿…é¡»ç”¨è‹±æ–‡æ¸¸æˆåæœç´¢è‡³å°‘ä¸€æ¬¡ï¼ˆè‹±æ–‡æœç´¢ç»“æœé€šå¸¸æœ€ä¸°å¯Œï¼‰
- å¦‚æœæ¸¸æˆå¯èƒ½æ˜¯æ—¥æœ¬å¼€å‘/æ—¥æ–‡å—ä¼—ï¼ˆå¦‚æ—¥å¼ RPGã€è§†è§‰å°è¯´ã€åŒäººæ¸¸æˆï¼‰ï¼Œ
  ä¹Ÿç”¨æ—¥æ–‡åæœç´¢ï¼ˆæœç´¢ã€Œã‚²ãƒ¼ãƒ å ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€æˆ–ã€Œã‚²ãƒ¼ãƒ å æ„Ÿæƒ³ã€ï¼‰
- ç”¨ä¸­æ–‡æ¸¸æˆåä¹Ÿæœç´¢ä¸€æ¬¡
- ä¸è¦ä»…ä¾èµ–ä¸­æ–‡æœç´¢ç»“æœï¼Œå¾ˆå¤šç‹¬ç«‹/å°ä¼—æ¸¸æˆå‡ ä¹æ²¡æœ‰ä¸­æ–‡èµ„æ–™ï¼Œ
  ä½†è‹±æ–‡æˆ–æ—¥æ–‡ç¤¾åŒºå¯èƒ½æœ‰ä¸°å¯Œçš„è®¨è®º
- æ ¹æ®æ¸¸æˆçš„å¼€å‘å•†/å‘è¡Œå•†å›½ç±ï¼Œåˆ¤æ–­å“ªç§è¯­è¨€æœç´¢æ›´å¯èƒ½è·å¾—æœ‰æ•ˆä¿¡æ¯
- å¦‚æœå¯¹è¿™ä¸ªæ¸¸æˆå·²ç»éå¸¸äº†è§£ï¼Œå¯ä»¥å°‘æœæˆ–ä¸æœï¼›å¦‚æœä¸å¤ªç¡®å®šï¼Œå¤šæœå‡ æ¬¡
- æœç´¢ç»“æœä»…ç”¨äºè¾…åŠ©ä½ çš„å†™ä½œï¼Œä¸è¦ç…§æŠ„æœç´¢åˆ°çš„æ–‡å­—
- ç‰¹åˆ«æ³¨æ„æœç´¢è¯¥æ¸¸æˆçš„ç¼ºç‚¹å’Œè´Ÿé¢è¯„ä»·ï¼Œå› ä¸ºæç¤ºè¯è¦æ±‚å¿…é¡»åŒ…å«è¿™äº›å†…å®¹

ğŸ“Š ä¿¡æ¯é‡è¯„ä¼°ä¸å›é€€ç­–ç•¥ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š
- æœç´¢å®Œæˆåï¼Œè¯·ä¸¥æ ¼è¯„ä¼°æœç´¢ç»“æœä¸­"ä¸è¿™ä¸ªæ¸¸æˆæœ¬èº«ç›´æ¥ç›¸å…³"çš„æœ‰æ•ˆä¿¡æ¯æ¯”ä¾‹
- æ³¨æ„ï¼šæ¸¸æˆåç§°å¯èƒ½ä¸å…¶ä»–äº‹ç‰©åŒåï¼Œæœç´¢ç»“æœä¸­å¯èƒ½æœ‰å¤§é‡ä¸ç›¸å…³å†…å®¹ï¼Œè¿™äº›ä¸ç®—æœ‰æ•ˆä¿¡æ¯
- âš ï¸ å›é€€è§„åˆ™ï¼šå¦‚æœè”ç½‘æœç´¢å‘ç°ç½‘ç»œä¸Šå…³äºè¿™ä¸ªæ¸¸æˆçš„æœ‰æ•ˆä¿¡æ¯ä¸¥é‡ä¸è¶³ï¼ˆå¦‚åªæœåˆ°
  ä¸ç›¸å…³ç»“æœã€æˆ–åªæœ‰å¯¥å¯¥å‡ å¥ï¼‰ï¼Œä½ å¿…é¡»å›é€€åˆ°ä¸»è¦ä¾é ä¸Šé¢æä¾›çš„ Steam è¯„æµ‹å†…å®¹æ¥
  æ’°å†™æ¸¸æˆè¯´æ˜ã€‚è¯·æ³¨æ„ï¼šå³ä½¿å…¨ä½“æœç´¢ç»“æœæ•°é‡å¾ˆå¤šï¼Œä½†å¦‚æœå¤§éƒ¨åˆ†éƒ½æ˜¯ä¸ç›¸å…³ä¿¡æ¯ï¼Œ
  ä¹Ÿåº”å½“è§†ä¸º"ç½‘ç»œæœ‰æ•ˆä¿¡æ¯ä¸è¶³"è€Œå›é€€åˆ° Steam è¯„æµ‹ã€‚
  åªæœ‰å½“è”ç½‘æœç´¢å’Œ Steam è¯„æµ‹ä¿¡æ¯éƒ½ä¸¥é‡ä¸è¶³æ—¶ï¼Œæ‰æ ‡æ³¨ INSUFFICIENT:true
- å¦‚æœè”ç½‘æœç´¢å‘ç°æœ‰æ•ˆä¿¡æ¯å¾ˆä¸°å¯Œå°±å†™"ç›¸å½“å¤š"ï¼Œ
  å‡ ä¹æ²¡æœ‰ç›¸å…³ä¿¡æ¯å°±å†™"ç›¸å½“å°‘"ã€‚
  å¯é€‰å€¼ï¼šç›¸å½“å¤š / è¾ƒå¤š / ä¸­ç­‰ / è¾ƒå°‘ / ç›¸å½“å°‘ï¼‰

âš ï¸ æœ€ç»ˆè¯­è¨€è¦æ±‚ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ï¼š
æ— è®ºä½ æœç´¢åˆ°çš„å‚è€ƒèµ„æ–™æ˜¯è‹±æ–‡ã€æ—¥æ–‡è¿˜æ˜¯å…¶ä»–è¯­è¨€ï¼Œä½ ã€å¿…é¡»ã€‘ä½¿ç”¨ç®€ä½“ä¸­æ–‡æ’°å†™æœ€ç»ˆçš„æ¸¸æˆè¯´æ˜ç¬”è®°ï¼Œä¸¥ç¦è¾“å‡ºä»»ä½•éä¸­æ–‡çš„æ­£æ–‡å†…å®¹ã€‚
ä¸¥ç¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚ **ç²—ä½“**ã€## æ ‡é¢˜ï¼‰ï¼Œä¸¥ç¦ä½¿ç”¨åˆ†æ®µå¼å°æ ‡é¢˜ï¼ˆå¦‚ã€ŒGameplay:ã€ã€ã€ŒReviews:ã€ï¼‰ï¼Œ
å¿…é¡»æ˜¯çº¯æ–‡æœ¬å•è¡Œä¸­æ–‡å™è¿°ã€‚"""


class SteamAIGenerator:
    """ä½¿ç”¨ AI API ç”Ÿæˆæ¸¸æˆè¯´æ˜ç¬”è®° â€” æ”¯æŒ Anthropic (Claude) å’Œ OpenAI å…¼å®¹ API"""

    # â”€â”€ å·²çŸ¥ API æä¾›å•†é…ç½® â”€â”€
    PROVIDERS = {
        'anthropic': {
            'name': 'Anthropic (Claude)',
            'api_url': 'https://api.anthropic.com/v1/messages',
            'models': [
                'claude-opus-4-6',
                'claude-opus-4-5-20251101-thinking',
                'claude-sonnet-4-5-20250929',
                'claude-haiku-4-5-20251001',
            ],
            'default_model': 'claude-sonnet-4-5-20250929',
            'key_prefix': 'sk-ant-',
        },
        'openai': {
            'name': 'OpenAI',
            'api_url': 'https://api.openai.com/v1/chat/completions',
            'models': [
                'gpt-4o', 'gpt-4o-mini', 'gpt-4.1', 'gpt-4.1-mini',
                'gpt-4.1-nano', 'o3-mini',
            ],
            'default_model': 'gpt-4o-mini',
            'key_prefix': 'sk-',
        },
        'deepseek': {
            'name': 'DeepSeek',
            'api_url': 'https://api.deepseek.com/v1/chat/completions',
            'models': ['deepseek-chat', 'deepseek-reasoner'],
            'default_model': 'deepseek-chat',
            'key_prefix': 'sk-',
        },
        'openai_compat': {
            'name': 'è‡ªå®šä¹‰ (OpenAI å…¼å®¹)',
            'api_url': '',
            'models': [],
            'default_model': '',
            'key_prefix': '',
        },
    }

    def __init__(self, api_key: str, model: str = None,
                 provider: str = 'anthropic', api_url: str = None):
        self.api_key = api_key
        self.provider = provider
        self._last_debug_info = ""
        self.model = model or self.PROVIDERS.get(provider, {}).get(
            'default_model', 'claude-sonnet-4-5-20250929')
        # å…è®¸è‡ªå®šä¹‰ API URLï¼ˆç”¨äº OpenAI å…¼å®¹çš„ç¬¬ä¸‰æ–¹æœåŠ¡ï¼‰
        if api_url:
            self.api_url = api_url
        else:
            self.api_url = self.PROVIDERS.get(provider, {}).get(
                'api_url', self.PROVIDERS['anthropic']['api_url'])

    @classmethod
    def detect_provider(cls, api_key: str) -> str:
        """æ ¹æ® API Key å‰ç¼€è‡ªåŠ¨æ£€æµ‹æä¾›å•†
        æ³¨æ„: ä»…å¯¹æ˜ç¡®çš„å‰ç¼€ï¼ˆå¦‚ sk-ant-ï¼‰è‡ªåŠ¨åˆ‡æ¢ï¼Œ
        é€šç”¨ sk- å‰ç¼€ä¸è‡ªåŠ¨åˆ‡æ¢ï¼ˆå¯èƒ½æ˜¯ä¸­è½¬æœåŠ¡çš„ Keyï¼‰ã€‚
        """
        key = api_key.strip()
        if key.startswith('sk-ant-'):
            return 'anthropic'
        # é€šç”¨ sk- å¼€å¤´çš„ Key ä¸å†è‡ªåŠ¨åˆ‡æ¢ï¼Œå› ä¸ºä¸­è½¬æœåŠ¡ä¹Ÿå¯èƒ½ä½¿ç”¨ sk- å‰ç¼€
        # ç”¨æˆ·éœ€è¦æ‰‹åŠ¨é€‰æ‹©æä¾›å•†
        return None  # è¿”å› None è¡¨ç¤ºæ— æ³•è‡ªåŠ¨æ£€æµ‹

    # å‚è€ƒèµ„æ–™æœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰â€” è¶…è¿‡æ­¤é•¿åº¦ä¼šæˆªæ–­è¯„æµ‹æ–‡æœ¬ï¼Œ
    # é¿å…å¤§é‡å‚è€ƒèµ„æ–™"æ·¹æ²¡"æ ¼å¼å’Œå†…å®¹æŒ‡ä»¤
    MAX_EXTRA_CONTEXT_CHARS = 3000

    def generate_note(self, game_name: str, app_id: str,
                      extra_context: str = "",
                      system_prompt: str = "",
                      use_web_search: bool = False) -> tuple:
        """ä¸ºå•ä¸ªæ¸¸æˆç”Ÿæˆç¬”è®°å†…å®¹

        Returns: (text: str, model: str, confidence: str,
                  info_volume: str, is_insufficient: bool, quality: str)

        æ¶ˆæ¯ç»“æ„è®¾è®¡åŸåˆ™ï¼ˆv6.0ï¼‰ï¼š
        - LLM å¯¹æ¶ˆæ¯çš„ã€å¼€å¤´ã€‘å’Œã€æœ«å°¾ã€‘æœ€ä¸ºæ•æ„Ÿ
        - å‚è€ƒèµ„æ–™ï¼ˆè¯„æµ‹ã€å•†åº—è¯¦æƒ…ï¼‰æ”¾åœ¨ä¸­é—´
        - è”ç½‘æœç´¢è§¦å‘æŒ‡ä»¤æ”¾åœ¨å‚è€ƒèµ„æ–™ä¹‹å‰ï¼ˆè®©æ¨¡å‹å…ˆæœç´¢å†çœ‹èµ„æ–™ï¼‰
        - å†…å®¹è¦æ±‚æ¸…å•å’Œæ ¼å¼è¦æ±‚æ”¾åœ¨æ¶ˆæ¯ã€æœ€æœ«å°¾ã€‘ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ä½ç½®ï¼‰
        - å…ƒæ•°æ®è¾“å‡ºæ ¼å¼æ”¾åœ¨å†…å®¹è¦æ±‚ä¹‹å‰ï¼ˆæ¬¡ä¼˜å…ˆçº§ï¼‰
        """
        # â”€â”€ ç¬¬ä¸€æ®µï¼šä»»åŠ¡å£°æ˜ + è”ç½‘æœç´¢è§¦å‘ï¼ˆå¦‚æœ‰ï¼‰â”€â”€
        user_msg = f"è¯·ä¸ºä»¥ä¸‹ Steam æ¸¸æˆæ’°å†™æ¸¸æˆè¯´æ˜ç¬”è®°ï¼š\n\n"
        user_msg += f"æ¸¸æˆåç§°ï¼š{game_name}\n"
        user_msg += f"Steam AppIDï¼š{app_id}\n"

        # è”ç½‘æœç´¢è§¦å‘æ”¾åœ¨å‚è€ƒèµ„æ–™ä¹‹å‰ï¼Œè®©æ¨¡å‹å…ˆæœç´¢
        if use_web_search:
            user_msg += ("\nğŸ” è”ç½‘æœç´¢å·²å¯ç”¨â€”â€”è¯·å…ˆç”¨ web_search æœç´¢è¿™ä¸ªæ¸¸æˆçš„"
                         "å®é™…æ¸¸ç©ä½“éªŒã€ç¤¾åŒºå£ç¢‘ã€é€šå…³æ—¶é•¿å’Œå¸¸è§ç¼ºç‚¹ï¼Œå†å¼€å§‹æ’°å†™ã€‚\n")

        # â”€â”€ ç¬¬äºŒæ®µï¼šå‚è€ƒèµ„æ–™ï¼ˆä¸­é—´ä½ç½®ï¼Œè¢«æŒ‡ä»¤åŒ…è£¹ï¼‰â”€â”€
        if extra_context:
            # æˆªæ–­è¿‡é•¿çš„å‚è€ƒèµ„æ–™
            if len(extra_context) > self.MAX_EXTRA_CONTEXT_CHARS:
                extra_context = (extra_context[:self.MAX_EXTRA_CONTEXT_CHARS]
                                 + "\nâ€¦ï¼ˆå‚è€ƒèµ„æ–™å·²æˆªæ–­ï¼‰")
            user_msg += ("\n"
                         "â•”â•â•â•â•â• ä»¥ä¸‹æ˜¯å‚è€ƒèµ„æ–™ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸¥ç¦ç…§æŠ„æˆ–é€æ¡æ€»ç»“ï¼‰â•â•â•â•â•â•—\n"
                         f"{extra_context}\n"
                         "â•šâ•â•â•â•â• å‚è€ƒèµ„æ–™ç»“æŸ â•â•â•â•â•â•\n"
                         "\n"
                         "âš ï¸ é‡è¦æé†’ï¼šä»¥ä¸Šå‚è€ƒèµ„æ–™åªæ˜¯å¸®ä½ äº†è§£è¿™ä¸ªæ¸¸æˆçš„ç´ æã€‚\n"
                         "ä½ çš„ä»»åŠ¡æ˜¯ç”¨è‡ªå·±çš„è¯å†™ä¸€æ®µè¿è´¯è‡ªç„¶çš„æ¸¸æˆè¯´æ˜ï¼Œ"
                         "åƒæœ‹å‹èŠå¤©ä¸€æ ·å¨“å¨“é“æ¥ã€‚ä¸è¦å˜æˆã€Œè¯„æµ‹æ‘˜è¦ã€æˆ–ã€Œä¿¡æ¯ç½—åˆ—ã€ã€‚\n")

        # â”€â”€ ç¬¬ä¸‰æ®µï¼šå…ƒæ•°æ®è¾“å‡ºæ ¼å¼ â”€â”€
        user_msg += ("\nåœ¨ä½ çš„å›å¤æœ€æœ«å°¾ï¼Œç”¨ä»¥ä¸‹æ ¼å¼é€è¡Œæ ‡æ³¨å…ƒæ•°æ®ï¼ˆæ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼‰ï¼š\n"
                     "\n")

        # ä¿¡æ¯é‡è¯„ä¼°æŒ‡å¼•
        if use_web_search:
            user_msg += (
                'INFO_VOLUME:ï¼ˆè¯·ä¸¥æ ¼æ ¹æ®ä½ çš„è”ç½‘æœç´¢ç»“æœæ¥åˆ¤æ–­ã€Œä¸è¿™ä¸ªæ¸¸æˆæœ¬èº«ç›´æ¥ç›¸å…³ã€çš„'
                'æœ‰æ•ˆä¿¡æ¯å å…¨éƒ¨æœç´¢ç»“æœçš„æ¯”ä¾‹â€”â€”æ³¨æ„ï¼Œæ¸¸æˆåå¯èƒ½æœå‡ºå¾ˆå¤šä¸ç›¸å…³çš„ç»“æœï¼Œ'
                'åªæœ‰ç¡®å®åœ¨è®¨è®ºè¿™ä¸ªæ¸¸æˆæœ¬èº«çš„ç©æ³•ã€è¯„ä»·ã€ä½“éªŒç­‰å†…å®¹æ‰ç®—æœ‰æ•ˆä¿¡æ¯ã€‚'
                'å¦‚æœæœç´¢ç»“æœä¸­æœ‰æ•ˆä¿¡æ¯å¾ˆä¸°å¯Œå°±å†™"ç›¸å½“å¤š"ï¼Œ'
                'å‡ ä¹æ²¡æœ‰ç›¸å…³ä¿¡æ¯å°±å†™"ç›¸å½“å°‘"ã€‚'
                'å¯é€‰å€¼ï¼šç›¸å½“å¤š / è¾ƒå¤š / ä¸­ç­‰ / è¾ƒå°‘ / ç›¸å½“å°‘ï¼‰\n')
        else:
            user_msg += (
                'INFO_VOLUME:ï¼ˆè¯·æ ¹æ®ä¸Šé¢æä¾›çš„å‚è€ƒèµ„æ–™ï¼ˆSteam å•†åº—è¯¦æƒ… + ç©å®¶è¯„æµ‹ï¼‰'
                'ä»¥åŠä½ è‡ªèº«è®­ç»ƒæ•°æ®ä¸­å¯¹è¿™ä¸ªæ¸¸æˆçš„äº†è§£ç¨‹åº¦ï¼Œç»¼åˆåˆ¤æ–­ä½ æŒæ¡çš„'
                'ã€Œä¸è¿™ä¸ªæ¸¸æˆæœ¬èº«ç›´æ¥ç›¸å…³ã€çš„æœ‰æ•ˆä¿¡æ¯é‡â€”â€”æ³¨æ„ï¼Œæœ‰äº› Steam è¯„æµ‹å¯èƒ½'
                'æ˜¯ç©ç¬‘ã€ä¸æ¸¸æˆå†…å®¹æ— å…³æˆ–ä¿¡æ¯é‡æä½ï¼Œè¿™ç±»ä¸ç®—æœ‰æ•ˆä¿¡æ¯ã€‚'
                'å¦‚æœæœ‰æ•ˆä¿¡æ¯å¾ˆä¸°å¯Œå°±å†™"ç›¸å½“å¤š"ï¼Œ'
                'å‡ ä¹æ²¡æœ‰æœ‰æ•ˆä¿¡æ¯å°±å†™"ç›¸å½“å°‘"ã€‚'
                'å¯é€‰å€¼ï¼šç›¸å½“å¤š / è¾ƒå¤š / ä¸­ç­‰ / è¾ƒå°‘ / ç›¸å½“å°‘ï¼‰\n')

        user_msg += (
            'INSUFFICIENT:ï¼ˆå¦‚æœä½ æŒæ¡çš„æœ‰æ•ˆä¿¡æ¯å®åœ¨å¤ªå°‘ï¼Œä»¥è‡³äºä½ è®¤ä¸º'
            'ç»å¯¹ä¸å¯èƒ½å†™å‡ºä¸€æ®µæœ‰æ„ä¹‰çš„ã€å¯¹è¯»è€…æœ‰å¸®åŠ©çš„æ¸¸æˆè¯´æ˜ï¼Œå°±å†™ trueã€‚'
            'åªè¦è¿˜èƒ½å†™å‡ºå¤§è‡´é è°±çš„ä»‹ç»å°±å†™ falseã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆé«˜çš„é—¨æ§›â€”â€”'
            'åªæœ‰çœŸçš„å‡ ä¹ä¸€æ— æ‰€çŸ¥æ—¶æ‰å†™ trueã€‚'
            'âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼šå¦‚æœè”ç½‘æœç´¢ä¿¡æ¯ä¸è¶³ä½†ä¸Šé¢æä¾›çš„ Steam è¯„æµ‹å†…å®¹'
            'ä»æœ‰è¶³å¤Ÿå‚è€ƒä»·å€¼ï¼Œä½ åº”è¯¥åŸºäºè¯„æµ‹å†…å®¹æ’°å†™è¯´æ˜å¹¶å†™ falseã€‚'
            'åªæœ‰è”ç½‘æœç´¢å’Œ Steam è¯„æµ‹éƒ½ä¸¥é‡ä¸è¶³æ—¶æ‰å†™ trueã€‚ï¼‰\n'
            'CONFIDENCE:å¾ˆé«˜ æˆ– CONFIDENCE:è¾ƒé«˜ æˆ– CONFIDENCE:ä¸­ç­‰ '
            'æˆ– CONFIDENCE:è¾ƒä½ æˆ– CONFIDENCE:å¾ˆä½\n'
            'ï¼ˆç¡®ä¿¡ç¨‹åº¦å–å†³äºä½ å¯¹è¿™ä¸ªæ¸¸æˆçš„äº†è§£ç¨‹åº¦â€”â€”'
            'å¦‚æœè¿™ä¸ªæ¸¸æˆä½ å¾ˆç†Ÿæ‚‰ã€ä¿¡æ¯ç¡®å®šæ€§é«˜å°±å†™"å¾ˆé«˜"ï¼Œ'
            'å¦‚æœæ˜¯æ¯”è¾ƒå†·é—¨/ä¸å¤ªäº†è§£çš„æ¸¸æˆå°±å†™"è¾ƒä½"æˆ–"å¾ˆä½"ã€‚ï¼‰\n'
            'QUALITY:ç›¸å½“å¥½ æˆ– QUALITY:è¾ƒå¥½ æˆ– QUALITY:ä¸­ç­‰ '
            'æˆ– QUALITY:è¾ƒå·® æˆ– QUALITY:ç›¸å½“å·®\n'
            'ï¼ˆæ¸¸æˆæ€»ä½“è´¨é‡æ˜¯ä½ ç»¼åˆæ‰€æœ‰ä¿¡æ¯åå¯¹è¿™ä¸ªæ¸¸æˆè´¨é‡çš„å®¢è§‚åˆ¤æ–­â€”â€”'
            'åŒ…æ‹¬ç©æ³•è®¾è®¡ã€å†…å®¹é‡ã€å®Œæˆåº¦ã€ç¤¾åŒºå£ç¢‘ç­‰ã€‚'
            'å¦‚æœæ˜¯å£ç¢‘æå¥½çš„ç²¾å“å°±å†™"ç›¸å½“å¥½"ï¼Œ'
            'å¦‚æœæ˜¯è´¨é‡å ªå¿§çš„æ¸¸æˆå°±å†™"è¾ƒå·®"æˆ–"ç›¸å½“å·®"ã€‚'
            'âš ï¸ æ³¨æ„ï¼šè¿™æ˜¯å¯¹æ¸¸æˆæœ¬èº«è´¨é‡çš„è¯„ä¼°ï¼Œä¸æ˜¯å¯¹ä½ å†™çš„è¯´æ˜çš„è¯„ä¼°ã€‚ï¼‰\n'
            '\n'
            'âš ï¸ å¦‚æœä½ åˆ¤å®š INSUFFICIENT:trueï¼Œåˆ™ä¸éœ€è¦è¾“å‡ºæ¸¸æˆè¯´æ˜æ­£æ–‡ï¼Œ'
            'åªéœ€è¦è¾“å‡ºä¸Šé¢å››è¡Œå…ƒæ•°æ®æ ‡ç­¾å³å¯ã€‚\n'
        )

        # â”€â”€ ç¬¬å››æ®µï¼ˆæœ€æœ«å°¾ = æœ€é«˜ä¼˜å…ˆçº§ï¼‰ï¼šå†…å®¹è¦æ±‚æ¸…å• + æ ¼å¼è¦æ±‚ â”€â”€
        # è¿™æ˜¯ç”¨æˆ·æ¶ˆæ¯çš„æœ€åéƒ¨åˆ†ï¼ŒLLM å¯¹æ­¤æœ€ä¸ºæ•æ„Ÿ
        user_msg += (
            "\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            "ğŸ“‹ ä»¥ä¸‹æ˜¯ä½ ã€å¿…é¡»éµå®ˆã€‘çš„å†…å®¹è¦æ±‚å’Œæ ¼å¼è¦æ±‚ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ï¼š\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            "\n"
            "ã€å†…å®¹è¦æ±‚æ¸…å•ã€‘â€” ç¼ºä¸€ä¸å¯ï¼Œè¾“å‡ºå‰é€æ¡è‡ªæŸ¥ï¼š\n"
            "â–¡ ç¬¬ä¸€å¥è¯æ˜¯å¦æœ‰æ¦‚æ‹¬æ€§ï¼ˆå¦‚ã€ŒXXX æ˜¯ä¸€æ¬¾â€¦â€¦çš„æ¸¸æˆã€ï¼‰ï¼Ÿ\n"
            "â–¡ æ˜¯å¦å…·ä½“æè¿°äº†ã€Œç°åœ¨æ‰“å¼€è¿™ä¸ªæ¸¸æˆï¼Œå‰å‡ åˆ†é’Ÿä¼šçœ‹åˆ°ä»€ä¹ˆã€åšä»€ä¹ˆã€ï¼Ÿ"
            "ï¼ˆâŒ ç¦æ­¢ç”¨ã€Œä¸Šæ‰‹éš¾åº¦é€‚ä¸­ã€ã€Œæœ‰ä¸€å®šé—¨æ§›ã€ç­‰æ¨¡ç³Šæ¦‚æ‹¬ä»£æ›¿ï¼ï¼‰\n"
            "â–¡ æ˜¯å¦è¯´æ˜äº†æ³¨æ„åŠ›æŠ•å…¥ç¨‹åº¦å’Œå•æ¬¡æ¸¸ç©æ—¶é•¿ï¼Ÿ\n"
            "â–¡ æ˜¯å¦æåˆ°äº†ç½‘ç»œå£ç¢‘ / ç¤¾åŒºè¯„ä»·ï¼Ÿ\n"
            "â–¡ æ˜¯å¦æœ‰ç¼ºç‚¹å’Œä¸é€‚åˆçš„äººç¾¤ï¼Ÿ\n"
            "â–¡ æ˜¯å¦è¯´äº†é€‚åˆçš„æ¸¸ç©æƒ…æ™¯ï¼ˆè·Ÿè°ç©ã€ä»€ä¹ˆåœºåˆï¼‰ï¼Ÿ\n"
            "â–¡ æ˜¯å¦æ‰€æœ‰æœ¯è¯­éƒ½é™„å¸¦äº†é€šä¿—è§£é‡Šï¼Ÿ\n"
            "â–¡ å…¨æ–‡æ˜¯å¦å®Œå…¨æ²¡æœ‰æåŠä»·æ ¼ã€æ€§ä»·æ¯”ã€æ‰“æŠ˜ç­‰ä¸é’±ç›¸å…³çš„å†…å®¹ï¼Ÿ\n"
            "\n"
            "ã€æ ¼å¼è¦æ±‚ã€‘â€” è¿åä»»ä½•ä¸€æ¡éƒ½æ˜¯ä¸åˆæ ¼çš„è¾“å‡ºï¼š\n"
            "âœ¦ çº¯æ–‡æœ¬å•è¡Œï¼Œç¦æ­¢æ¢è¡Œ\n"
            "âœ¦ ç¦æ­¢ BBCode æ ‡ç­¾ï¼ˆ[p] [h1] [b] ç­‰å…¨éƒ¨ç¦æ­¢ï¼‰\n"
            "âœ¦ ç¦æ­¢ Markdown æ ¼å¼ï¼ˆç¦æ­¢ **ç²—ä½“**ã€## æ ‡é¢˜ç­‰ï¼‰\n"
            "âœ¦ ç¦æ­¢åˆ†æ®µå¼å°æ ‡é¢˜ï¼ˆå¦‚ã€Œåˆæ¬¡æ‰“å¼€çš„ä½“éªŒï¼šã€ã€Œè®¤çŸ¥èµ„æºï¼šã€ï¼‰ï¼Œ"
            "æ‰€æœ‰ä¿¡æ¯èå…¥ä¸€æ®µè¿è´¯å™è¿°\n"
            "âœ¦ å¯é€‚åº¦ä½¿ç”¨ emojiï¼ˆğŸ“Œâœ…âš ï¸ğŸ—ºï¸âš”ï¸ğŸ“ğŸ¯ï¼‰ä½†è¦å…‹åˆ¶\n"
            "âœ¦ å»ºè®® 200-500 å­—\n"
            "âœ¦ å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡\n"
            "\n"
            "è¯·ç›´æ¥è¾“å‡ºæ¸¸æˆè¯´æ˜æ­£æ–‡ï¼ˆä¸Šè¿°å†…å®¹æ¸…å•å…¨éƒ¨è¦†ç›–ï¼‰ï¼Œ"
            "ç„¶ååœ¨æœ«å°¾é™„ä¸Šå››è¡Œå…ƒæ•°æ®æ ‡ç­¾ã€‚ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–å‰ç¼€ã€‚"
        )

        prompt = system_prompt.strip() if system_prompt.strip() else AI_SYSTEM_PROMPT

        # è”ç½‘æœç´¢æ—¶è¿½åŠ æœç´¢ç­–ç•¥æŒ‡å¼•åˆ°ç³»ç»Ÿæç¤ºè¯
        if use_web_search:
            prompt += AI_WEB_SEARCH_ADDENDUM

        if self.provider == 'anthropic':
            return self._call_anthropic(prompt, user_msg,
                                        use_web_search=use_web_search)
        else:
            return self._call_openai_compat(prompt, user_msg,
                                            use_web_search=use_web_search)

    def _call_anthropic(self, system_prompt: str, user_msg: str,
                        use_web_search: bool = False) -> tuple:
        """è°ƒç”¨ Anthropic (Claude) API"""
        # æ£€æµ‹æ˜¯å¦é€šè¿‡ç¬¬ä¸‰æ–¹ä»£ç†ï¼ˆè‡ªå®šä¹‰URLï¼‰
        _default_url = self.PROVIDERS['anthropic']['api_url']
        _is_proxy = (self.api_url != _default_url)

        result = self._call_anthropic_inner(
            system_prompt, user_msg, use_web_search=use_web_search)

        # â”€â”€ ä»£ç†è”ç½‘æœç´¢çš„å…œåº•ï¼šä¸¤æ­¥æ³• â”€â”€
        # ç¬¬ä¸‰æ–¹ä»£ç†å¤„ç† web_search æ—¶ä¼šé‡æ„è¯·æ±‚ï¼Œç»å¸¸ä¸¢å¼ƒ system promptï¼Œ
        # å¯¼è‡´ Claude ç”¨è‹±æ–‡å›å¤æˆ–ä¸éµå®ˆæ ¼å¼ï¼ˆMarkdownã€åˆ†æ®µç­‰ï¼‰ã€‚
        # æ­¤æ—¶ç¬¬ä¸€æ­¥çš„è¾“å‡ºä»åŒ…å«æœ‰ä»·å€¼çš„æœç´¢ä¿¡æ¯ã€‚
        # ç­–ç•¥ï¼šæ£€æµ‹åˆ°è¾“å‡ºä¸ºéä¸­æ–‡æˆ–æ ¼å¼ä¸ç¬¦æ—¶ï¼Œä»¥ç¬¬ä¸€æ­¥è¾“å‡ºä½œä¸º"å‚è€ƒèµ„æ–™"ï¼Œ
        # å‘èµ·ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆä¸å¸¦ web_searchï¼‰ï¼Œè®© Claude æŒ‰æ ¼å¼é‡å†™ä¸ºä¸­æ–‡ã€‚
        # ç¬¬äºŒæ¬¡è°ƒç”¨ä¸æ¶‰åŠ web_searchï¼Œä»£ç†ä¸ä¼šå¹²é¢„ï¼Œsystem prompt æ­£å¸¸ç”Ÿæ•ˆã€‚
        if _is_proxy and use_web_search and result[0]:
            full_text = result[0]
            _cn_chars = len(re.findall(r'[\u4e00-\u9fff]', full_text))
            _total_chars = len(full_text.strip())
            _is_non_chinese = (_total_chars > 50
                               and _cn_chars < _total_chars * 0.15)
            _has_fmt_issues = bool(
                re.search(r'\*\*[^*]+\*\*', full_text)
            ) or full_text.count('\n') > 8
            # æ–°å¢ï¼šæ£€æµ‹å†…å®¹è¿‡çŸ­ï¼ˆä½äº 80 ä¸­æ–‡å­—ç¬¦ï¼Œè¯´æ˜å¯èƒ½æ²¡éµå®ˆå†…å®¹è¦æ±‚ï¼‰
            _is_too_short = (_cn_chars < 80 and not result[4])  # æ’é™¤ INSUFFICIENT
            # æ–°å¢ï¼šæ£€æµ‹åˆ†æ®µæ ‡é¢˜ï¼ˆæç¤ºè¯æ˜ç¡®ç¦æ­¢ï¼‰
            _has_section_headers = bool(re.search(
                r'(?:^|\n)\s*(?:[\w\u4e00-\u9fff]+[:ï¼š]\s*\n|'
                r'#{1,6}\s+|'
                r'\*\*[\u4e00-\u9fff]+(?:[:ï¼š]|ï¼š)\*\*)',
                full_text))
            # æ–°å¢ï¼šæ£€æµ‹ BBCode æ ‡ç­¾
            _has_bbcode = bool(re.search(
                r'\[/?(?:p|h[1-6]|b|i|u|url|img|list|olist|strike|spoiler)\b',
                full_text, re.IGNORECASE))

            _need_rewrite = (_is_non_chinese or _has_fmt_issues
                             or _is_too_short or _has_section_headers
                             or _has_bbcode)

            if _need_rewrite:
                # è¯Šæ–­åŸå› 
                _reasons = []
                if _is_non_chinese:
                    _reasons.append(f"éä¸­æ–‡ï¼ˆä¸­æ–‡ {_cn_chars}/{_total_chars}ï¼‰")
                if _has_fmt_issues:
                    _reasons.append(f"æ ¼å¼ä¸ç¬¦ï¼ˆMarkdown/æ¢è¡Œ{full_text.count(chr(10))}å¤„ï¼‰")
                if _is_too_short:
                    _reasons.append(f"å†…å®¹è¿‡çŸ­ï¼ˆä»… {_cn_chars} ä¸­æ–‡å­—ç¬¦ï¼‰")
                if _has_section_headers:
                    _reasons.append("åŒ…å«åˆ†æ®µæ ‡é¢˜")
                if _has_bbcode:
                    _reasons.append("åŒ…å« BBCode æ ‡ç­¾")
                _reason = " + ".join(_reasons)
                self._last_debug_info += (
                    f"\nâš ï¸ è”ç½‘æœç´¢è¾“å‡º{_reason}ï¼Œ"
                    "å¯åŠ¨ç¬¬äºŒæ­¥ï¼šç”¨æ­£å¸¸è°ƒç”¨é‡å†™â€¦\n"
                )
                # æ„é€ ç¬¬äºŒæ­¥çš„ user messageï¼š
                # å°†ç¬¬ä¸€æ­¥çš„è¾“å‡ºä½œä¸ºå‚è€ƒèµ„æ–™ï¼Œè¦æ±‚æŒ‰åŸå§‹æ ¼å¼é‡å†™ä¸ºä¸­æ–‡
                rewrite_user_msg = (
                    f"è¯·ä¸ºä»¥ä¸‹ Steam æ¸¸æˆæ’°å†™æ¸¸æˆè¯´æ˜ç¬”è®°ï¼š\n\n"
                    f"ä»¥ä¸‹æ˜¯å…³äºè¿™ä¸ªæ¸¸æˆçš„è¯¦ç»†å‚è€ƒèµ„æ–™ï¼ˆæ¥è‡ªè”ç½‘æœç´¢ç»“æœï¼‰ï¼Œ"
                    f"è¯·åŸºäºè¿™äº›ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæç¤ºè¯çš„è¦æ±‚æ’°å†™ä¸­æ–‡æ¸¸æˆè¯´æ˜ï¼š\n\n"
                    f"â•”â•â•â•â•â• è”ç½‘æœç´¢å‚è€ƒèµ„æ–™ â•â•â•â•â•â•—\n"
                    f"{full_text}\n"
                    f"â•šâ•â•â•â•â• å‚è€ƒèµ„æ–™ç»“æŸ â•â•â•â•â•â•\n\n"
                )
                # ä¹ŸåŒ…å«åŸå§‹ user_msg ä¸­çš„ Steam è¯„æµ‹ç­‰ä¿¡æ¯
                # ä»åŸå§‹ user_msg ä¸­æå–æ¸¸æˆåå’Œ AppID
                _name_match = re.search(r'æ¸¸æˆåç§°ï¼š(.+)', user_msg)
                _appid_match = re.search(r'Steam AppIDï¼š(\d+)', user_msg)
                if _name_match:
                    rewrite_user_msg += f"æ¸¸æˆåç§°ï¼š{_name_match.group(1)}\n"
                if _appid_match:
                    rewrite_user_msg += f"Steam AppIDï¼š{_appid_match.group(1)}\n"
                # æå–åŸå§‹ user_msg ä¸­çš„å‚è€ƒèµ„æ–™éƒ¨åˆ†ï¼ˆSteam è¯„æµ‹ç­‰ï¼‰
                _ref_match = re.search(
                    r'(â•”â•â•â•â•â• ä»¥ä¸‹æ˜¯å‚è€ƒèµ„æ–™.*?â•šâ•â•â•â•â• å‚è€ƒèµ„æ–™ç»“æŸ â•â•â•â•â•â•)',
                    user_msg, re.DOTALL)
                if _ref_match:
                    rewrite_user_msg += f"\n{_ref_match.group(1)}\n"
                # æ·»åŠ å…ƒæ•°æ®è¾“å‡ºè¦æ±‚ï¼ˆä»åŸå§‹ user_msg ä¸­æˆªå–ï¼‰
                _meta_match = re.search(
                    r'(åœ¨ä½ çš„å›å¤æœ€æœ«å°¾.*?)$', user_msg, re.DOTALL)
                if _meta_match:
                    rewrite_user_msg += f"\n{_meta_match.group(1)}"
                else:
                    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ‰‹åŠ¨æ·»åŠ ç®€åŒ–ç‰ˆå…ƒæ•°æ®è¦æ±‚
                    rewrite_user_msg += (
                        "\nè¯·ç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬å†…å®¹ï¼ˆå•è¡Œï¼Œæ— æ¢è¡Œï¼Œæ—  BBCode æ ‡ç­¾ï¼‰ã€‚\n"
                        "åœ¨å›å¤æœ€æœ«å°¾æ ‡æ³¨ï¼š\n"
                        "INFO_VOLUME:ï¼ˆç›¸å½“å¤š/è¾ƒå¤š/ä¸­ç­‰/è¾ƒå°‘/ç›¸å½“å°‘ï¼‰\n"
                        "INSUFFICIENT:false\n"
                        "CONFIDENCE:ï¼ˆå¾ˆé«˜/è¾ƒé«˜/ä¸­ç­‰/è¾ƒä½/å¾ˆä½ï¼‰\n"
                        "QUALITY:ï¼ˆç›¸å½“å¥½/è¾ƒå¥½/ä¸­ç­‰/è¾ƒå·®/ç›¸å½“å·®ï¼‰\n"
                    )

                # ç¬¬äºŒæ­¥è°ƒç”¨ï¼šä¸å¸¦ web_searchï¼Œsystem prompt æ­£å¸¸ä¼ é€’
                _step1_debug = self._last_debug_info  # ä¿å­˜ç¬¬ä¸€æ­¥çš„è°ƒè¯•ä¿¡æ¯
                result = self._call_anthropic_inner(
                    system_prompt, rewrite_user_msg, use_web_search=False)
                # åˆå¹¶ä¸¤æ­¥çš„è°ƒè¯•ä¿¡æ¯
                self._last_debug_info = (
                    _step1_debug
                    + "\n\n=== ç¬¬äºŒæ­¥ï¼ˆé‡å†™ä¸ºä¸­æ–‡ï¼‰===\n"
                    + self._last_debug_info
                    + "\nâœ… ç¬¬äºŒæ­¥é‡å†™å®Œæˆã€‚\n"
                )

        return result

    def _call_anthropic_inner(self, system_prompt: str, user_msg: str,
                              use_web_search: bool = False) -> tuple:
        """è°ƒç”¨ Anthropic (Claude) API çš„å†…éƒ¨å®ç°"""
        is_thinking = 'thinking' in self.model.lower()

        # æ£€æµ‹æ˜¯å¦é€šè¿‡ç¬¬ä¸‰æ–¹ä»£ç†ï¼ˆè‡ªå®šä¹‰URLï¼‰
        _default_url = self.PROVIDERS['anthropic']['api_url']
        _is_proxy = (self.api_url != _default_url)

        # â”€â”€ ä»£ç†é˜²æŠ¤ï¼šå°†ç³»ç»Ÿæç¤ºè¯æ³¨å…¥ç”¨æˆ·æ¶ˆæ¯ â”€â”€
        # ç¬¬ä¸‰æ–¹ä»£ç†ï¼ˆnew-api/one-api ç­‰ï¼‰åœ¨è½¬å‘ Anthropic è¯·æ±‚æ—¶ï¼Œ
        # ç»å¸¸ä¸¢å¼ƒæˆ–æˆªæ–­ "system" å­—æ®µï¼Œå¯¼è‡´æ¨¡å‹å®Œå…¨çœ‹ä¸åˆ°æç¤ºè¯ã€‚
        # è§£å†³æ–¹æ¡ˆï¼šä»£ç†åœºæ™¯ä¸‹ï¼Œå°†ç³»ç»Ÿæç¤ºè¯ä½œä¸ºç”¨æˆ·æ¶ˆæ¯çš„å¼€å¤´æ³¨å…¥ï¼Œ
        # åŒæ—¶ä¿ç•™åŸå§‹ "system" å­—æ®µï¼ˆå…¼å®¹æ­£ç¡®å¤„ç† system çš„ä»£ç†ï¼‰ã€‚
        _actual_user_msg = user_msg
        if _is_proxy:
            _actual_user_msg = (
                "ã€ç³»ç»ŸæŒ‡ä»¤ â€” è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹å…¨éƒ¨è¦æ±‚ã€‘\n"
                f"{system_prompt}\n"
                "ã€ç³»ç»ŸæŒ‡ä»¤ç»“æŸã€‘\n\n"
                f"{user_msg}"
            )

        payload_dict = {
            "model": self.model,
            "max_tokens": 16000 if is_thinking else 4096,
            "system": system_prompt,
            "messages": [{"role": "user", "content": _actual_user_msg}]
        }

        # thinking æ¨¡å‹éœ€è¦é¢å¤–å‚æ•°
        if is_thinking:
            payload_dict["thinking"] = {
                "type": "enabled",
                "budget_tokens": 10000
            }

        # Web Search å·¥å…·
        if use_web_search:
            payload_dict["tools"] = [
                {
                    "type": "web_search_20250305",
                    "name": "web_search",
                    "max_uses": 5,
                }
            ]

        payload = json.dumps(payload_dict).encode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "User-Agent": "SteamNotesGen/5.9",
            "Accept": "application/json",
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01",
        }

        # ç¬¬ä¸‰æ–¹ä»£ç†ï¼ˆnew-api/one-api ç­‰ï¼‰é€šå¸¸éœ€è¦ Bearer è®¤è¯
        # åŒæ—¶å‘é€ä¸¤ç§è®¤è¯å¤´ä»¥å…¼å®¹å®˜æ–¹ API å’Œå„ç±»ä»£ç†
        if _is_proxy:
            headers["Authorization"] = f"Bearer {self.api_key}"

        # Web Search éœ€è¦ beta header
        if use_web_search:
            headers["anthropic-beta"] = "web-search-2025-03-05"

        req = urllib.request.Request(
            self.api_url,
            data=payload,
            headers=headers,
            method="POST",
        )

        # æ„å»ºè°ƒè¯•ä¿¡æ¯ï¼ˆåœ¨å¼‚å¸¸æ—¶ä½¿ç”¨ï¼‰
        self._last_debug_info = self._build_debug_info(
            url=self.api_url, headers=headers, payload=payload_dict,
            method="POST"
        )

        # è”ç½‘æœç´¢æ—¶ AI éœ€è¦æ›´å¤šæ—¶é—´ï¼ˆå¤šæ¬¡æœç´¢+ç»¼åˆï¼‰
        _timeout = 180 if use_web_search else 120
        with _urlopen(req, timeout=_timeout) as resp:
            resp_body = resp.read().decode("utf-8")
            self._last_debug_info += (
                f"\n--- å“åº” ---\n"
                f"HTTP çŠ¶æ€ç : {resp.status}\n"
                f"å“åº”å¤´: {dict(resp.headers)}\n"
                f"å“åº”ä½“ (å‰500å­—): {resp_body[:500]}\n"
            )
            data = json.loads(resp_body)

        content_blocks = data.get("content", [])
        text_parts = [b["text"] for b in content_blocks if b.get("type") == "text"]

        # â”€â”€ å…³é”®ï¼šè”ç½‘æœç´¢æ—¶åªå–æœ€åä¸€ä¸ªæœ‰å®è´¨å†…å®¹çš„ text block â”€â”€
        # å¯ç”¨ web search åï¼ŒAPI è¿”å›çš„ content æ•°ç»„åŒ…å«å¤šä¸ª text blockï¼š
        #   text("Let me search...")  â†’  tool_use  â†’  tool_result  â†’
        #   text("Based on my search...")  â†’  tool_use  â†’  tool_result  â†’
        #   text("ã€Šæ¸¸æˆåã€‹æ˜¯ä¸€æ¬¾â€¦â€¦CONFIDENCE:â€¦â€¦")   â† è¿™æ‰æ˜¯æ­£æ–‡
        # ä¸­é—´çš„ text block æ˜¯ AI çš„æ€è€ƒ/è®¡åˆ’æ€§æ–‡å­—ï¼Œä¸æ˜¯æ¸¸æˆè¯´æ˜ã€‚
        # åªæœ‰æœ€åä¸€ä¸ª text block åŒ…å«æˆ‘ä»¬éœ€è¦çš„æ­£æ–‡å’Œå…ƒæ•°æ®æ ‡ç­¾ã€‚
        if use_web_search and len(text_parts) > 1:
            full_text = self._select_best_text_block(text_parts)
        else:
            full_text = "\n".join(text_parts)

        # å…¼å®¹ï¼šç¬¬ä¸‰æ–¹ä»£ç†å¯èƒ½è¿”å› OpenAI æ ¼å¼ï¼ˆchoices[0].message.contentï¼‰
        if not full_text and data.get("choices"):
            choices = data["choices"]
            if choices:
                full_text = choices[0].get("message", {}).get("content", "")

        actual_model = data.get("model", self.model)

        return self._extract_confidence(full_text, actual_model)

    def _call_openai_compat(self, system_prompt: str, user_msg: str,
                            use_web_search: bool = False) -> tuple:
        """è°ƒç”¨ OpenAI å…¼å®¹ API (OpenAI, DeepSeek, åŠå…¶ä»–å…¼å®¹æœåŠ¡)"""
        payload_dict = {
            "model": self.model,
            "max_tokens": 4096,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_msg},
            ]
        }

        # Web Search å·¥å…·ï¼ˆæ˜¯å¦å¯ç”¨å–å†³äºä¸­è½¬æœåŠ¡å•†ï¼‰
        if use_web_search:
            payload_dict["tools"] = [
                {
                    "type": "web_search_20250305",
                    "name": "web_search",
                    "max_uses": 5,
                }
            ]
        payload = json.dumps(payload_dict).encode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "User-Agent": "SteamNotesGen/5.9",
            "Accept": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }

        # Web Search éœ€è¦ beta headerï¼ˆéƒ¨åˆ†ä¸­è½¬ä¼šé€ä¼ ç»™ä¸Šæ¸¸ Anthropicï¼‰
        if use_web_search:
            headers["anthropic-beta"] = "web-search-2025-03-05"

        req = urllib.request.Request(
            self.api_url,
            data=payload,
            headers=headers,
            method="POST",
        )

        # æ„å»ºè°ƒè¯•ä¿¡æ¯
        self._last_debug_info = self._build_debug_info(
            url=self.api_url, headers=headers, payload=payload_dict,
            method="POST"
        )

        _timeout = 180 if use_web_search else 120
        with _urlopen(req, timeout=_timeout) as resp:
            resp_body = resp.read().decode("utf-8")
            self._last_debug_info += (
                f"\n--- å“åº” ---\n"
                f"HTTP çŠ¶æ€ç : {resp.status}\n"
                f"å“åº”å¤´: {dict(resp.headers)}\n"
                f"å“åº”ä½“ (å‰500å­—): {resp_body[:500]}\n"
            )
            data = json.loads(resp_body)

        full_text = ""

        # ä¼˜å…ˆå°è¯• OpenAI æ ¼å¼: data.choices[0].message.content
        choices = data.get("choices", [])
        if choices:
            full_text = choices[0].get("message", {}).get("content", "")

        # å…¼å®¹ Anthropic åŸç”Ÿæ ¼å¼ï¼ˆéƒ¨åˆ†ä¸­è½¬ç›´æ¥é€ä¼ ï¼‰
        if not full_text and data.get("content"):
            content_blocks = data.get("content", [])
            text_parts = [b["text"] for b in content_blocks
                          if b.get("type") == "text"]
            # è”ç½‘æœç´¢æ—¶åªå–æœ€åä¸€ä¸ªæœ‰å®è´¨å†…å®¹çš„ text blockï¼ˆåŒ _call_anthropicï¼‰
            if use_web_search and len(text_parts) > 1:
                full_text = self._select_best_text_block(text_parts)
            else:
                full_text = "\n".join(text_parts)

        actual_model = data.get("model", self.model)

        return self._extract_confidence(full_text, actual_model)

    @staticmethod
    def _select_best_text_block(text_parts: list) -> str:
        """ä»å¤šä¸ª text block ä¸­é€‰æ‹©åŒ…å«æ­£æ–‡çš„é‚£ä¸ªã€‚

        è”ç½‘æœç´¢æ—¶ API è¿”å›å¤šä¸ª text blockï¼Œå…¶ä¸­å¤§éƒ¨åˆ†æ˜¯ AI çš„æœç´¢è®¡åˆ’
        å’Œæ€è€ƒæ–‡å­—ï¼Œåªæœ‰ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€åä¸€ä¸ªï¼‰åŒ…å«å®é™…çš„æ¸¸æˆè¯´æ˜æ­£æ–‡ã€‚

        é€‰æ‹©ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. ä»åå¾€å‰æ‰¾ç¬¬ä¸€ä¸ªåŒæ—¶åŒ…å«å…ƒæ•°æ®æ ‡ç­¾å’Œè¶³å¤Ÿä¸­æ–‡å†…å®¹çš„ block
        2. ä»åå¾€å‰æ‰¾ç¬¬ä¸€ä¸ªåŒ…å«å…ƒæ•°æ®æ ‡ç­¾çš„ block
        3. ä»åå¾€å‰æ‰¾ç¬¬ä¸€ä¸ªåŒ…å«è¶³å¤Ÿä¸­æ–‡å†…å®¹ï¼ˆâ‰¥30å­—ï¼‰çš„ block
        4. å–æœ€åä¸€ä¸ªéç©º block
        """
        _meta_pattern = re.compile(
            r'(?:CONFIDENCE|QUALITY|INFO_VOLUME|INSUFFICIENT)[:ï¼š]')

        # ç­–ç•¥1ï¼šåŒæ—¶æœ‰å…ƒæ•°æ®æ ‡ç­¾ + è¶³å¤Ÿä¸­æ–‡ï¼ˆæœ€ç†æƒ³ï¼‰
        for i in range(len(text_parts) - 1, -1, -1):
            part = text_parts[i]
            if (_meta_pattern.search(part)
                    and len(re.findall(r'[\u4e00-\u9fff]', part)) >= 30):
                return part

        # ç­–ç•¥2ï¼šåªæœ‰å…ƒæ•°æ®æ ‡ç­¾
        for i in range(len(text_parts) - 1, -1, -1):
            if _meta_pattern.search(text_parts[i]):
                return text_parts[i]

        # ç­–ç•¥3ï¼šè¶³å¤Ÿçš„ä¸­æ–‡å†…å®¹
        for i in range(len(text_parts) - 1, -1, -1):
            if (text_parts[i].strip()
                    and len(re.findall(r'[\u4e00-\u9fff]', text_parts[i])) >= 30):
                return text_parts[i]

        # ç­–ç•¥4ï¼šæœ€åä¸€ä¸ªéç©º block
        for i in range(len(text_parts) - 1, -1, -1):
            if text_parts[i].strip():
                return text_parts[i]

        return text_parts[-1] if text_parts else ""

    def _build_debug_info(self, url: str, headers: dict, payload: dict,
                          method: str = "POST") -> str:
        """æ„å»ºè°ƒè¯•ä¿¡æ¯å­—ç¬¦ä¸²ï¼ˆè„±æ•ï¼‰"""
        safe_headers = {}
        for k, v in headers.items():
            if k.lower() in ("x-api-key", "authorization"):
                if len(v) > 16:
                    safe_headers[k] = v[:10] + "..." + v[-4:]
                else:
                    safe_headers[k] = v[:4] + "..."
            else:
                safe_headers[k] = v

        safe_payload = dict(payload)
        if "system" in safe_payload and len(str(safe_payload["system"])) > 200:
            safe_payload["system"] = str(safe_payload["system"])[:200] + "...(æˆªæ–­)"
        if "messages" in safe_payload:
            safe_msgs = []
            for m in safe_payload["messages"]:
                sm = dict(m)
                if len(str(sm.get("content", ""))) > 300:
                    sm["content"] = str(sm["content"])[:300] + "...(æˆªæ–­)"
                safe_msgs.append(sm)
            safe_payload["messages"] = safe_msgs

        lines = [
            "=== API è°ƒè¯•ä¿¡æ¯ ===",
            f"æ—¶é—´: {datetime.now().isoformat()}",
            f"æä¾›å•†: {self.provider}",
            f"æ¨¡å‹: {self.model}",
            f"API URL: {url}",
            f"HTTP æ–¹æ³•: {method}",
            f"è¯·æ±‚å¤´: {json.dumps(safe_headers, ensure_ascii=False, indent=2)}",
            f"è¯·æ±‚ä½“: {json.dumps(safe_payload, ensure_ascii=False, indent=2)}",
        ]
        return "\n".join(lines)

    @staticmethod
    def _extract_confidence(full_text: str, actual_model: str) -> tuple:
        """ä» AI è¾“å‡ºä¸­æå–ç¡®ä¿¡ç¨‹åº¦ã€ä¿¡æ¯é‡è¯„ä¼°ã€ä¿¡æ¯ä¸è¶³æ ‡è®°å’Œè´¨é‡è¯„ä¼°
        
        Returns: (text, model, confidence, info_volume, is_insufficient, quality)
        """
        confidence = "ä¸­ç­‰"
        info_volume = "ä¸­ç­‰"
        is_insufficient = False
        quality = "ä¸­ç­‰"

        # â”€â”€ å…ˆè®°å½•ç¬¬ä¸€ä¸ªå…ƒæ•°æ®æ ‡ç­¾çš„ä½ç½®ï¼ˆç”¨äºåç»­æ­£æ–‡å®šä½ï¼‰ â”€â”€
        # å¿…é¡»åœ¨å‰¥ç¦»å…ƒæ•°æ®ä¹‹å‰è®°å½•ï¼Œå¦åˆ™é”šç‚¹ä¿¡æ¯ä¼šä¸¢å¤±
        _first_meta_pos = None
        _meta_pos_match = re.search(
            r'(?:^|\n)\s*(?:INFO_VOLUME|INSUFFICIENT|CONFIDENCE|QUALITY)[:ï¼š]',
            full_text, re.MULTILINE
        )
        if _meta_pos_match:
            _first_meta_pos = _meta_pos_match.start()

        # æå– INSUFFICIENT æ ‡è®°
        insuf_match = re.search(
            r'INSUFFICIENT[:ï¼š]\s*(true|false|æ˜¯|å¦)',
            full_text, re.IGNORECASE
        )
        if insuf_match:
            val = insuf_match.group(1).lower()
            is_insufficient = val in ('true', 'æ˜¯')
            full_text = re.sub(r'\n*INSUFFICIENT[:ï¼š].*$', '', full_text,
                               flags=re.MULTILINE).strip()

        # æå– INFO_VOLUME æ ‡è®°
        vol_match = re.search(
            r'INFO_VOLUME[:ï¼š]\s*(ç›¸å½“å¤š|è¾ƒå¤š|ä¸­ç­‰|è¾ƒå°‘|ç›¸å½“å°‘)',
            full_text
        )
        if vol_match:
            info_volume = vol_match.group(1)
            full_text = re.sub(r'\n*INFO_VOLUME[:ï¼š].*$', '', full_text,
                               flags=re.MULTILINE).strip()

        # æå– QUALITY æ ‡è®°
        qual_match = re.search(
            r'QUALITY[:ï¼š]\s*(ç›¸å½“å¥½|è¾ƒå¥½|ä¸­ç­‰|è¾ƒå·®|ç›¸å½“å·®)',
            full_text
        )
        if qual_match:
            quality = qual_match.group(1)
            full_text = re.sub(r'\n*QUALITY[:ï¼š].*$', '', full_text,
                               flags=re.MULTILINE).strip()

        # æå– CONFIDENCE æ ‡è®°
        conf_match = re.search(
            r'CONFIDENCE[:ï¼š]\s*(å¾ˆé«˜|è¾ƒé«˜|ä¸­ç­‰|è¾ƒä½|å¾ˆä½|ç›¸å½“é«˜|ç›¸å½“ä½)',
            full_text
        )
        if conf_match:
            confidence = conf_match.group(1)
            full_text = re.sub(r'\n*CONFIDENCE[:ï¼š].*$', '', full_text,
                               flags=re.MULTILINE).strip()

        # â”€â”€ æ¸…ç†ç¬¬ä¸‰æ–¹ä»£ç†ï¼ˆä¸­è½¬æœåŠ¡ï¼‰å¯èƒ½æ³„éœ²çš„åŸå§‹å·¥å…·è°ƒç”¨æ ‡è®° â”€â”€
        # æŸäº›ä»£ç†æœªæ­£ç¡®æ‹†åˆ† content blocksï¼Œå°† <function_calls>ã€<invoke>ã€
        # <thinking>ã€<search_results> ç­‰ XML æ ‡ç­¾ä½œä¸ºçº¯æ–‡æœ¬æ··å…¥ text å—ä¸­ã€‚
        # å¿…é¡»åœ¨æå–æ­£æ–‡å‰å½»åº•æ¸…é™¤ï¼Œå¦åˆ™ä¼šå‡ºç°åœ¨æœ€ç»ˆç¬”è®°ä¸­ã€‚
        # 1. ç§»é™¤å®Œæ•´çš„ XML å—ï¼ˆå«å†…å®¹ï¼‰ï¼ŒåŒ…æ‹¬ <parameter> å—
        for tag in ('function_calls', 'invoke', 'thinking', 'search_results',
                     'search_quality_reflection', 'result', 'parameter',
                     'antml:thinking', 'antml:function_calls', 'antml:invoke',
                     'antml:parameter', 'tool_result', 'tool_use',
                     'tool_call', 'tool_calls'):
            full_text = re.sub(
                rf'<{re.escape(tag)}[^>]*>.*?</{re.escape(tag)}>',
                '', full_text, flags=re.DOTALL
            )
        # 2. ç§»é™¤æ®‹ä½™çš„è‡ªé—­åˆæˆ–å­¤ç«‹ XML æ ‡ç­¾ï¼ˆå¦‚ </invoke> </function_calls> ç­‰ï¼‰
        full_text = re.sub(
            r'</?(?:function_calls|invoke|thinking|parameter|search_results|'
            r'search_quality_reflection|result|antml:\w+|tool_result|tool_use|'
            r'tool_call|tool_calls)[^>]*>',
            '', full_text
        )
        
        # 3. æ¸…é™¤è£¸éœ²çš„ JSON æ ¼å¼å·¥å…·è°ƒç”¨ï¼ˆXML æ ‡ç­¾è¢«éƒ¨åˆ†æ¸…é™¤åå¯èƒ½æ®‹ç•™ï¼‰
        full_text = re.sub(
            r'\s*\{\s*"name"\s*:\s*"web_search"\s*,\s*"arguments"\s*:\s*\{[^}]*\}\s*\}\s*',
            '', full_text
        )
        
        full_text = full_text.strip()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # æ ¸å¿ƒæ¸…ç†ï¼šå®šä½ä¸­æ–‡æ­£æ–‡èµ·å§‹ä½ç½®ï¼Œä¸¢å¼ƒä¹‹å‰çš„éæ­£æ–‡å†…å®¹
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # è”ç½‘æœç´¢æ—¶ï¼ŒAI çš„è¾“å‡ºå¯èƒ½æ˜¯ï¼š
        #   [è‹±æ–‡æ€è€ƒ/æœç´¢è®¡åˆ’] + [ä¸­æ–‡æ­£æ–‡] + [å…ƒæ•°æ®æ ‡ç­¾]
        # æˆ–è€…ä¸­è½¬æœåŠ¡æŠŠæ‰€æœ‰ text block åˆå¹¶åå˜æˆä¸€å¤§æ®µæ··åˆæ–‡æœ¬ã€‚
        #
        # ç­–ç•¥ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸­æ–‡å­—ç¬¦çš„ä½ç½®ï¼Œç„¶åå¾€å‰å›æº¯åˆ°è¯¥å¥å­çš„èµ·å§‹ä½ç½®
        # ï¼ˆæ¸¸æˆåå¯èƒ½æ˜¯è‹±æ–‡å¦‚ "Hollow Knight æ˜¯ä¸€æ¬¾..."ï¼‰ï¼Œ
        # ä¸¢å¼ƒä¹‹å‰æ‰€æœ‰çš„è‹±æ–‡æ€è€ƒ/æœç´¢è®¡åˆ’æ–‡å­—ã€‚
        #
        # è¿™æ¯”é€æ¡æ­£åˆ™åŒ¹é…è‹±æ–‡å‰ç¼€ç¨³å®šå¾—å¤šï¼Œå› ä¸ºä¸éœ€è¦ç©·ä¸¾ AI å¯èƒ½è¯´çš„
        # æ¯ä¸€ç§è‹±æ–‡æ€è€ƒå¥å¼ã€‚
        
        _first_cn = re.search(r'[\u4e00-\u9fff]', full_text)
        
        if _first_cn and _first_cn.start() > 0:
            # ç¬¬ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ä¹‹å‰æœ‰éä¸­æ–‡å†…å®¹ï¼ˆå¯èƒ½æ˜¯æ€è€ƒæ€§å‰ç¼€ï¼‰
            _first_cn_pos = _first_cn.start()
            _text_before_cn = full_text[:_first_cn_pos]
            
            # ä»ç¬¬ä¸€ä¸ªä¸­æ–‡å­—ç¬¦å¾€å‰å›æº¯ï¼Œå¯»æ‰¾"æ¸¸æˆè¯´æ˜å¥"çš„èµ·å§‹ä½ç½®
            # æ¸¸æˆåå¯èƒ½æ˜¯è‹±æ–‡ï¼ˆå¦‚ "Hollow Knight æ˜¯ä¸€æ¬¾..."ï¼‰
            # ä¹Ÿå¯èƒ½æ˜¯å¸¦ç‰¹æ®Šå­—ç¬¦çš„ï¼ˆå¦‚ ".T.E.S.T: Expected Behaviour æ˜¯ä¸€æ¬¾..."ï¼‰
            #
            # æ‰¾æœ€åä¸€ä¸ªè‹±æ–‡å¥å­ç»“å°¾ï¼ˆå¥å·+ç©ºæ ¼ï¼‰ï¼Œæ’é™¤æ¸¸æˆåä¸­çš„ç‚¹å·
            _best_boundary = 0
            
            for _sb in re.finditer(
                r'(?<![.A-Z])'     # å‰é¢ä¸æ˜¯ç‚¹å·æˆ–å¤§å†™å­—æ¯ï¼ˆæ’é™¤ .T.E.S.T ç­‰ï¼‰
                r'\.'              # å¥å·
                r'(?!\.)'          # åé¢ä¸æ˜¯ç‚¹å·ï¼ˆæ’é™¤çœç•¥å· ...ï¼‰
                r'\s+',            # åè·Ÿç©ºç™½
                _text_before_cn
            ):
                _best_boundary = _sb.end()
            
            # ä¹Ÿæ£€æŸ¥æ¢è¡Œä½œä¸ºè¾¹ç•Œ
            for _nl in re.finditer(r'\n\s*', _text_before_cn):
                if _nl.end() > _best_boundary:
                    _best_boundary = _nl.end()
            
            if _best_boundary > 0:
                full_text = full_text[_best_boundary:].lstrip()

        full_text = full_text.strip()

        # å…œåº•ï¼šå¦‚æœä¸Šé¢çš„é”šç‚¹æ–¹æ³•æ²¡ç”Ÿæ•ˆï¼ˆå¦‚æ­£æ–‡æœ¬èº«å°±æ˜¯è‹±æ–‡ï¼‰ï¼Œ
        # é€å¥æ¸…ç†æ®‹ä½™çš„æ˜æ˜¾æ€è€ƒæ€§å‰ç¼€
        _changed = True
        while _changed:
            _changed = False
            for pattern in (
                # è‹±æ–‡æ€è€ƒ/è®¡åˆ’æ€§å¥å­ï¼ˆå®½æ³›åŒ¹é…ï¼šä»¥å¸¸è§ AI æ€è€ƒå¼€å¤´è¯èµ·å§‹çš„è‹±æ–‡å¥å­ï¼‰
                r"^(?:I'll |I will |Let me |I need to |I should |I'm going to |"
                r"I have |I now have |The game'?s? |The search |Based on |"
                r"After |Now that |This is |Here'?s? |Looking at |"
                r"The web search |I can see |From the |According to |"
                r"Now I |First,? |Next,? |Finally,? |Overall,? )"
                r"[^\n]*?(?:\.\s*|\n)",
                # ä¸­æ–‡æ€è€ƒ/è®¡åˆ’æ€§å¥å­
                r"^(?:æˆ‘[æ¥å…ˆ]|è®©æˆ‘|æˆ‘éœ€è¦|æˆ‘[ä¼šå°†è¦]|æ¥ä¸‹æ¥æˆ‘)"
                r"(?:æœç´¢|æŸ¥[æ‰¾è¯¢]|æ£€ç´¢|äº†è§£|æ”¶é›†|è·å–|çœ‹çœ‹|æŸ¥ä¸€ä¸‹|æœä¸€ä¸‹).*?[ã€‚.]\s*",
                # "æ ¹æ®æœç´¢ç»“æœ"ç±»
                r"^æ ¹æ®(?:æœç´¢ç»“æœ|æˆ‘çš„æœç´¢|ç½‘ç»œä¿¡æ¯|ä»¥ä¸Šä¿¡æ¯)[ï¼Œ,].*?[ã€‚.]\s*",
                # "æœç´¢ç»“æœæ˜¾ç¤º"ç±»
                r"^(?:æœç´¢ç»“æœ|ç½‘ç»œä¸Šçš„ä¿¡æ¯|ç»¼åˆä»¥ä¸Šä¿¡æ¯)(?:æ˜¾ç¤º|è¡¨æ˜|è¯´æ˜)?[ï¼Œ,ï¼š:].*?[ã€‚.]\s*",
            ):
                new_text = re.sub(pattern, '', full_text, count=1,
                                  flags=re.IGNORECASE).strip()
                if new_text != full_text:
                    full_text = new_text
                    _changed = True

        # â”€â”€ åå¤„ç†ï¼šæ¸…ç† Markdown æ ¼å¼æ®‹ç•™å¹¶å¼ºåˆ¶å•è¡Œ â”€â”€
        # ç¬¬ä¸‰æ–¹ä»£ç† + è”ç½‘æœç´¢æ—¶ï¼Œæ¨¡å‹å¯èƒ½è¾“å‡º Markdown è€Œéçº¯æ–‡æœ¬
        # 1. Markdown ç²—ä½“ **text** â†’ text
        full_text = re.sub(r'\*\*(.+?)\*\*', r'\1', full_text)
        # 2. è¡Œå°¾å­¤ç«‹ * å·ï¼ˆMarkdown åˆ—è¡¨æ®‹ç•™ï¼‰
        full_text = re.sub(r'\s*\*\s*$', '', full_text, flags=re.MULTILINE)
        # 3. Markdown æ ‡é¢˜æ ‡è®° ## ...
        full_text = re.sub(r'(?:^|\n)\s*#{1,6}\s+', '', full_text)
        # 4. åˆå¹¶å¤šè¡Œä¸ºå•è¡Œï¼ˆæç¤ºè¯è¦æ±‚çº¯æ–‡æœ¬å•è¡Œï¼‰
        full_text = re.sub(r'\s*\n\s*', '', full_text)
        # 5. æ¸…ç†å¤šä½™ç©ºæ ¼
        full_text = re.sub(r'  +', ' ', full_text).strip()

        return full_text, actual_model, confidence, info_volume, is_insufficient, quality

    @staticmethod
    def get_game_name_from_steam(app_id: str) -> str:
        """é€šè¿‡ Steam Store API è·å–æ¸¸æˆåç§°"""
        url = f"https://store.steampowered.com/api/appdetails?appids={app_id}&l=schinese"
        try:
            req = urllib.request.Request(url, headers={
                "User-Agent": "SteamNotesGen/2.8"
            })
            with _urlopen(req, timeout=15) as resp:
                data = json.loads(resp.read().decode("utf-8"))
            app_data = data.get(str(app_id), {})
            if app_data.get("success"):
                return app_data["data"].get("name", f"AppID {app_id}")
        except Exception:
            pass
        return f"AppID {app_id}"

    @staticmethod
    def get_game_details_from_steam(app_id: str) -> dict:
        """é€šè¿‡ Steam Store API è·å–æ¸¸æˆçš„è¯¦ç»†ä¿¡æ¯ï¼ˆåç§°ã€å¼€å‘å•†ã€ç±»å‹ã€ç®€ä»‹ç­‰ï¼‰

        Returns: dict with keys: name, developers, publishers, genres,
                 categories, short_description, release_date, metacritic,
                 recommendations, etc. è‹¥å¤±è´¥è¿”å›ç©º dictã€‚
        """
        url = f"https://store.steampowered.com/api/appdetails?appids={app_id}&l=schinese"
        try:
            req = urllib.request.Request(url, headers={
                "User-Agent": "SteamNotesGen/2.8"
            })
            with _urlopen(req, timeout=15) as resp:
                data = json.loads(resp.read().decode("utf-8"))
            app_data = data.get(str(app_id), {})
            if app_data.get("success"):
                return app_data.get("data", {})
        except Exception:
            pass
        return {}

    @staticmethod
    def format_game_context(details: dict) -> str:
        """å°† Steam Store API è¿”å›çš„æ¸¸æˆè¯¦æƒ…æ ¼å¼åŒ–ä¸º AI å¯å‚è€ƒçš„æ–‡æœ¬æ‘˜è¦"""
        if not details:
            return ""
        parts = []
        name = details.get("name", "")
        if name:
            parts.append(f"æ¸¸æˆåç§°ï¼š{name}")
        # ç±»å‹
        app_type = details.get("type", "")
        if app_type:
            parts.append(f"ç±»å‹ï¼š{app_type}")
        # å¼€å‘å•† / å‘è¡Œå•†
        devs = details.get("developers", [])
        if devs:
            parts.append(f"å¼€å‘å•†ï¼š{', '.join(devs)}")
        pubs = details.get("publishers", [])
        if pubs:
            parts.append(f"å‘è¡Œå•†ï¼š{', '.join(pubs)}")
        # ç±»å‹æ ‡ç­¾
        genres = details.get("genres", [])
        if genres:
            genre_names = [g.get("description", "") for g in genres]
            parts.append(f"ç±»å‹æ ‡ç­¾ï¼š{', '.join(genre_names)}")
        # åˆ†ç±»ï¼ˆå•äºº/å¤šäºº/åœ¨çº¿ç­‰ï¼‰
        categories = details.get("categories", [])
        if categories:
            cat_names = [c.get("description", "") for c in categories]
            parts.append(f"åŠŸèƒ½ç‰¹æ€§ï¼š{', '.join(cat_names)}")
        # ç®€ä»‹
        short_desc = details.get("short_description", "")
        if short_desc:
            # å»é™¤ HTML æ ‡ç­¾
            clean_desc = re.sub(r'<[^>]+>', '', short_desc).strip()
            parts.append(f"å®˜æ–¹ç®€ä»‹ï¼š{clean_desc}")
        # è¯¦ç»†æè¿°ï¼ˆabout_the_game é€šå¸¸æ¯” detailed_description æ›´ä¸°å¯Œï¼‰
        about = details.get("about_the_game", "") or details.get(
            "detailed_description", "")
        if about:
            clean_about = re.sub(r'<[^>]+>', ' ', about).strip()
            clean_about = re.sub(r'\s+', ' ', clean_about)
            # æˆªå–å‰800å­—ç¬¦ï¼Œé¿å…è¿‡é•¿
            if len(clean_about) > 800:
                clean_about = clean_about[:800] + "â€¦"
            if clean_about and clean_about != (
                    re.sub(r'<[^>]+>', '', short_desc).strip() if short_desc
                    else ""):
                parts.append(f"è¯¦ç»†æè¿°ï¼š{clean_about}")
        # Metacritic
        mc = details.get("metacritic", {})
        if mc and mc.get("score"):
            parts.append(f"Metacritic è¯„åˆ†ï¼š{mc['score']}")
        # Steam è¯„ä»·æ•°
        recs = details.get("recommendations", {})
        if recs and recs.get("total"):
            parts.append(f"Steam è¯„ä»·æ•°ï¼š{recs['total']}")
        # å‘è¡Œæ—¥æœŸ
        rd = details.get("release_date", {})
        if rd and rd.get("date"):
            parts.append(f"å‘è¡Œæ—¥æœŸï¼š{rd['date']}")
            if rd.get("coming_soon"):
                parts.append("çŠ¶æ€ï¼šå°šæœªå‘å”®ï¼ˆæŠ¢å…ˆä½“éªŒæˆ–å³å°†å‘å”®ï¼‰")
        # æ”¯æŒçš„å¹³å°
        platforms = details.get("platforms", {})
        if platforms:
            plats = [p for p, v in platforms.items() if v]
            if plats:
                parts.append(f"æ”¯æŒå¹³å°ï¼š{', '.join(plats)}")
        # æ”¯æŒçš„è¯­è¨€
        langs = details.get("supported_languages", "")
        if langs:
            clean_langs = re.sub(r'<[^>]+>', '', langs).strip()
            if clean_langs:
                parts.append(f"æ”¯æŒè¯­è¨€ï¼š{clean_langs}")
        # æˆå°±æ•°é‡
        achieves = details.get("achievements", {})
        if achieves and achieves.get("total"):
            parts.append(f"Steam æˆå°±æ•°ï¼š{achieves['total']}")
        # DLC æ•°é‡
        dlc = details.get("dlc", [])
        if dlc:
            parts.append(f"DLC æ•°é‡ï¼š{len(dlc)}")
        # å†…å®¹æè¿°ï¼ˆæˆäººã€æš´åŠ›ç­‰æ ‡è®°ï¼‰
        content_desc = details.get("content_descriptors", {})
        if content_desc and content_desc.get("notes"):
            parts.append(f"å†…å®¹è­¦å‘Šï¼š{content_desc['notes']}")
        # æ˜¯å¦å…è´¹
        if details.get("is_free"):
            parts.append("ä»·æ ¼ï¼šå…è´¹")
        # æ˜¯å¦æŠ¢å…ˆä½“éªŒ
        if "Early Access" in str(genres):
            parts.append("âš ï¸ è¯¥æ¸¸æˆç›®å‰å¤„äºã€ŒæŠ¢å…ˆä½“éªŒã€é˜¶æ®µ")

        return "\n".join(parts)

    @staticmethod
    def get_game_reviews_from_steam(app_id: str, num_per_lang: int = 10) -> dict:
        """é€šè¿‡ Steam appreviews API è·å–ç©å®¶è¯„æµ‹æ–‡æœ¬å’Œè¯„åˆ†æ‘˜è¦ã€‚

        - ä½¿ç”¨ purchase_type=steam è¿‡æ»¤é Steam è´­ä¹°æ¥æºï¼ˆå¦‚å…è´¹ Keyï¼‰
        - è¿”å›åå†è¿‡æ»¤ received_for_free=true çš„è¯„æµ‹
        - åˆ†åˆ«è·å–ä¸­æ–‡å’Œè‹±æ–‡çš„ã€Œæœ€æœ‰å¸®åŠ©ã€è¯„æµ‹

        Returns: dict with keys:
            'query_summary': {review_score, review_score_desc, total_positive,
                              total_negative, total_reviews}
            'reviews': list of dicts with keys: text, voted_up, playtime,
                       language, helpful_count
            è‹¥å¤±è´¥è¿”å›ç©º dictã€‚
        """
        result = {'query_summary': {}, 'reviews': []}

        for lang in ('schinese', 'english'):
            url = (
                f"https://store.steampowered.com/appreviews/{app_id}"
                f"?json=1&language={lang}&filter=toprated"
                f"&purchase_type=steam&num_per_page={num_per_lang}"
            )
            try:
                req = urllib.request.Request(url, headers={
                    "User-Agent": "SteamNotesGen/4.5"
                })
                with _urlopen(req, timeout=15) as resp:
                    data = json.loads(resp.read().decode("utf-8"))
                if data.get("success") != 1:
                    continue

                # é¦–æ¬¡è·å–æ—¶ä¿å­˜ query_summaryï¼ˆä¸­æ–‡è¯·æ±‚çš„ summary å°±å¤Ÿäº†ï¼‰
                qs = data.get("query_summary", {})
                if not result['query_summary'] and qs:
                    result['query_summary'] = {
                        'review_score': qs.get('review_score', 0),
                        'review_score_desc': qs.get('review_score_desc', ''),
                        'total_positive': qs.get('total_positive', 0),
                        'total_negative': qs.get('total_negative', 0),
                        'total_reviews': qs.get('total_reviews', 0),
                    }

                for r in data.get("reviews", []):
                    # è¿‡æ»¤ï¼šå…è´¹è·å–çš„è¯„æµ‹
                    if r.get("received_for_free", False):
                        continue
                    review_text = r.get("review", "").strip()
                    if not review_text:
                        continue
                    author = r.get("author", {})
                    result['reviews'].append({
                        'text': review_text,
                        'voted_up': r.get("voted_up", True),
                        'playtime': round(
                            author.get("playtime_forever", 0) / 60, 1),
                        'language': lang,
                        'helpful_count': r.get("votes_up", 0),
                    })
            except Exception:
                continue

        return result

    @staticmethod
    def format_review_context(reviews_data: dict,
                              max_reviews: int = 8,
                              max_chars_per_review: int = 300) -> str:
        """å°† Steam è¯„æµ‹æ•°æ®æ ¼å¼åŒ–ä¸º AI å¯å‚è€ƒçš„æ–‡æœ¬æ‘˜è¦ã€‚

        åŒ…å«å¥½è¯„ç‡ã€è¯„ä»·ç­‰çº§ã€ä»¥åŠå¥½è¯„å’Œå·®è¯„çš„ä»£è¡¨æ€§æ–‡æœ¬æ‘˜å½•ã€‚
        """
        if not reviews_data:
            return ""
        parts = []

        # â”€â”€ è¯„åˆ†æ‘˜è¦ â”€â”€
        qs = reviews_data.get('query_summary', {})
        if qs:
            desc = qs.get('review_score_desc', '')
            pos = qs.get('total_positive', 0)
            neg = qs.get('total_negative', 0)
            total = qs.get('total_reviews', 0)
            if total > 0:
                pct = round(pos / total * 100, 1)
                parts.append(
                    f"Steam è¯„ä»·ç­‰çº§ï¼š{desc}ï¼ˆå¥½è¯„ç‡ {pct}%ï¼Œ"
                    f"å…± {total} æ¡è¯„ä»·ï¼Œ{pos} å¥½è¯„ / {neg} å·®è¯„ï¼‰")
            elif desc:
                parts.append(f"Steam è¯„ä»·ç­‰çº§ï¼š{desc}")

        # â”€â”€ è¯„æµ‹æ–‡æœ¬æ‘˜å½• â”€â”€
        reviews = reviews_data.get('reviews', [])
        if not reviews:
            return "\n".join(parts)

        # â”€â”€ ç©å®¶æ¸¸ç©æ—¶é•¿ç»Ÿè®¡ï¼ˆå¸®åŠ© AI åˆ¤æ–­æ—¶é—´æŠ•å…¥ï¼‰â”€â”€
        playtimes = sorted([r['playtime'] for r in reviews
                            if r['playtime'] > 0])
        if playtimes:
            median_pt = playtimes[len(playtimes) // 2]
            min_pt = playtimes[0]
            max_pt = playtimes[-1]
            parts.append(
                f"è¯„æµ‹è€…æ¸¸ç©æ—¶é•¿ï¼šä¸­ä½æ•° {median_pt}hï¼Œ"
                f"èŒƒå›´ {min_pt}h ~ {max_pt}hï¼ˆå…± {len(playtimes)} äººï¼‰")

        # æŒ‰å¥½è¯„/å·®è¯„åˆ†ç»„ï¼Œå„è‡ªæŒ‰æœ‰å¸®åŠ©æ•°æ’åº
        positive = sorted(
            [r for r in reviews if r['voted_up']],
            key=lambda r: r['helpful_count'], reverse=True)
        negative = sorted(
            [r for r in reviews if not r['voted_up']],
            key=lambda r: r['helpful_count'], reverse=True)

        # å–æœ€æœ‰å¸®åŠ©çš„å‡ æ¡ï¼ˆå¥½è¯„å¤šå–ï¼Œå·®è¯„ä¹Ÿè¦æœ‰ï¼‰
        n_pos = min(max(max_reviews * 2 // 3, 1), len(positive))
        n_neg = min(max(max_reviews - n_pos, 1), len(negative))
        if n_neg < max_reviews - n_pos and len(positive) > n_pos:
            n_pos = min(max_reviews - n_neg, len(positive))

        selected = ([('+', r) for r in positive[:n_pos]]
                    + [('-', r) for r in negative[:n_neg]])

        if selected:
            parts.append(
                "\n--- ä»¥ä¸‹æ˜¯çœŸå®ç©å®¶è¯„æµ‹æ‘˜å½•ï¼ˆä¾›å‚è€ƒï¼Œè¯·å‹¿ç…§æŠ„ï¼‰---")
            for tag, r in selected:
                text = r['text']
                if len(text) > max_chars_per_review:
                    text = text[:max_chars_per_review] + "â€¦"
                text = ' '.join(text.split())  # å»æ¢è¡Œå‹ç¼©ç©ºç™½
                emoji = 'ğŸ‘' if tag == '+' else 'ğŸ‘'
                pt = (f"{r['playtime']}h"
                      if r['playtime'] > 0 else "æœªçŸ¥æ—¶é•¿")
                parts.append(f"{emoji} [{pt}] {text}")

        return "\n".join(parts)
